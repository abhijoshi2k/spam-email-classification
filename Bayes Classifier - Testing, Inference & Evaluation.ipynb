{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "6e32d43ee9400bcbd351cf329268e62026260826e1d100b2fd0920263d797d36"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notebook Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "# Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_SPAM_PROB_FILE = 'SpamData/03_Testing/prob-spam.txt'\n",
    "TOKEN_HAM_PROB_FILE = 'SpamData/03_Testing/prob-nonspam.txt'\n",
    "TOKEN_ALL_PROB_FILE = 'SpamData/03_Testing/prob-all-tokens.txt'\n",
    "\n",
    "TEST_FEATURE_MATRIX = 'SpamData/03_Testing/test-features.txt'\n",
    "TEST_TARGET_FILE = 'SpamData/03_Testing/test-target.txt'\n",
    "\n",
    "VOCAB_SIZE = 2500"
   ]
  },
  {
   "source": [
    "# Load the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_test = np.loadtxt(TEST_FEATURE_MATRIX, delimiter=' ')\n",
    "# Target\n",
    "y_test = np.loadtxt(TEST_TARGET_FILE, delimiter=' ')\n",
    "# Token probabilities\n",
    "prob_token_spam = np.loadtxt(TOKEN_SPAM_PROB_FILE, delimiter=' ')\n",
    "prob_token_ham = np.loadtxt(TOKEN_HAM_PROB_FILE, delimiter=' ')\n",
    "prob_all_tokens = np.loadtxt(TOKEN_ALL_PROB_FILE, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1724, 2500)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1724,)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "source": [
    "# Calculating Joint Probability\n",
    "## Dot Product"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a = [1 2 3]\nb = [0 5 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([0, 5, 4])\n",
    "print('a =', a)\n",
    "print('b =', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "1*0 + 2*5 + 3*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of c is: (3, 2)\n[[0 6]\n [3 0]\n [5 1]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[0, 6], [3, 0], [5, 1]])\n",
    "print('Shape of c is:', c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[21  9]\nShape of dot product is: (2,)\n"
     ]
    }
   ],
   "source": [
    "print(a.dot(c))\n",
    "print('Shape of dot product is:', a.dot(c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[21, 9]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "[1*0 + 2*3 + 3*5, 1*6 + 2*0 + 3*1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1724, 2500)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "prob_token_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of dot product: (1724,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dot product:', X_test.dot(prob_token_spam).shape)"
   ]
  },
  {
   "source": [
    "## Set the Prior\n",
    "$$ P(Spam \\, | \\, X) = \\frac{P(X \\, | \\, Spam \\,) \\, P(Spam)}{P(X)}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROB_SPAM = 0.310989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ -4.40760872,  -5.25368353,  -4.99008596, ..., -10.30247059,\n",
       "        -8.83613352, -12.09423006])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "np.log(prob_token_spam)"
   ]
  },
  {
   "source": [
    "## Joint probability in log format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_log_spam = X_test.dot(np.log(prob_token_spam) - np.log(prob_all_tokens)) + np.log(PROB_SPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  24.27862556,    2.1604211 ,   20.5904407 , ..., -374.66032958,\n",
       "         -9.90362646, -112.01986139])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "joint_log_spam"
   ]
  },
  {
   "source": [
    "$$ P(Ham \\, | \\, X) = \\frac{P(X \\, | \\, Ham \\,) \\, (1 - P(Spam))}{P(X)}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_log_ham = X_test.dot(np.log(prob_token_ham) - np.log(prob_all_tokens)) + np.log(1 - PROB_SPAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-6.09702401e+01, -1.10100708e+01, -3.79679398e+01, ...,\n",
       "        6.09737116e+01, -5.82211832e-02,  2.44516960e+01])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "joint_log_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "joint_log_ham.size"
   ]
  },
  {
   "source": [
    "# Making Predictions\n",
    "### Checking for Higher Joint Probability\n",
    "$$ P(Spam \\, | \\, X) \\, > \\, P(Ham \\, | \\, x) $$\n",
    "**<center>OR</center>**\n",
    "\n",
    "$$ P(Spam \\, | \\, X) \\, < \\, P(Ham \\, | \\, x) $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = joint_log_spam > joint_log_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "prediction * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "source": [
    "### Simplify"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_log_spam = X_test.dot(np.log(prob_token_spam)) + np.log(PROB_SPAM)\n",
    "joint_log_ham = X_test.dot(np.log(prob_token_ham)) + np.log(1 - PROB_SPAM)"
   ]
  },
  {
   "source": [
    "# Metrix and Evaluation\n",
    "## Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Docs classified correctly: 1685\nDocs classified incorrectly: 39\n"
     ]
    }
   ],
   "source": [
    "correct_docs = (y_test == prediction).sum()\n",
    "print('Docs classified correctly:', correct_docs)\n",
    "num_docs_wrong = X_test.shape[0] - correct_docs\n",
    "print('Docs classified incorrectly:', num_docs_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9773781902552204"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Accuracy\n",
    "correct_docs/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fraction classified incorrectly is 2.26%\nAccuracy of the model is 97.74%\n"
     ]
    }
   ],
   "source": [
    "fraction_worng = num_docs_wrong/len(X_test)\n",
    "print('Fraction classified incorrectly is {:.2%}'.format(fraction_worng))\n",
    "print('Accuracy of the model is {:.2%}'.format(1 - fraction_worng))"
   ]
  }
 ]
}